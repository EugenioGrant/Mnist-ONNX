{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Service Client\n",
    "\n",
    "En este notebook vamos a consumir un servicio de machine learning. El servicio debe ser levantando con el script server.py por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Prediccion': 2}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# url del servicio\n",
    "url = 'http://127.0.0.1:1080/predict'\n",
    "\n",
    "# cuerpo del mensaje\n",
    "body = {\n",
    "    \"petal_length\": \"2.1\",\n",
    "    \"sepal_length\": \"2\",\n",
    "    \"petal_width\": \"0.5\",\n",
    "    \"sepal_width\": \"3\"\n",
    "}\n",
    "\n",
    "# enviamos los datos por POST\n",
    "response = requests.post(url, data=body)\n",
    "\n",
    "# imprimimos el mensaje\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 1: \n",
    "\n",
    "Modifique el server.py para que acepte requests por GET. Modifique el codigo del cliente para enviar los datos por GET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Prediccion': 2}\n"
     ]
    }
   ],
   "source": [
    "# DEFINA SU CLIENTE GET AQUI:\n",
    "response = requests.get(url, data=body)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EJERCICIO 2:\n",
    "\n",
    "* Entrene un modelo de machine learning con MNIST y salve su modelo en un archivo pickle. [https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html]\n",
    "* Modifique el server.py para que agregue la ruta /predict-number y que sea capaz de predecir si una imagen pertecene a un numero del 0 al 9\n",
    "* Va a enviar la imagen desde el cliente (este notebook) como un base64 hacia el server.py\n",
    "* el server.py va recibir la imagen la reconstruye en una imagen nuevamente y la manda al modelo de ML\n",
    "* la imagen que ingresa al server.py debe salvarla en un folder (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrenar MNIST y salvarlo en pickle\n",
    "from sklearn.datasets import fetch_openml, load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType, Int64TensorType, Int64TensorType, StringTensorType, DoubleTensorType, SequenceType, DictionaryType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import requests\n",
    "import base64\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('pca', PCA(n_components=150)),\n",
       "                ('lr', LogisticRegression(C=5))])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "MnistModel = Pipeline(steps=[('scaler',MinMaxScaler()),\n",
    "                             ('pca',PCA(n_components=150)),\n",
    "                             ('lr',LogisticRegression(C=5))])\n",
    "MnistModel.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"MnistLR.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(MnistModel, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_types = [('input', FloatTensorType([1, X.shape[1]]))]\n",
    "onx = convert_sklearn(MnistModel, initial_types=initial_types)\n",
    "with open(\"MnistLR.onnx\", \"wb\") as file:\n",
    "    file.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"NumberToProcess.png\"\n",
    "img = cv2.bitwise_not(cv2.imread(img_path, 0))\n",
    "encoded_string = base64.b64encode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Prediccion': 2}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://127.0.0.1:1080/predict-number'\n",
    "body = {\"ImageBase64\": encoded_string}\n",
    "response = requests.get(url, data=body)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}